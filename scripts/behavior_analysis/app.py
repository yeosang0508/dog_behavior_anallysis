import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from flask import Flask, request, jsonify
import cv2
from collections import Counter
import tempfile
from absl import logging

# Mediapipe ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
logging.set_verbosity(logging.ERROR)
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

# GPU/CPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# í–‰ë™ í´ë˜ìŠ¤ ì •ì˜
behavior_classes = {
    0: "ğŸŒŸ ëª¸ í”ë“¤ê¸° - í¥ í­ë°œ! ë‚˜ë§Œì˜ ëŒ„ìŠ¤ ë¬´ë¸Œ~",
    1: "ğŸ” ê³ ê°œ ëŒë¦¬ê¸° - 'ì–´ë””ì„ ê°€ ì†Œë¦¬ê°€?' ì§‘ì¤‘ ëª¨ë“œ ON!",
    2: "ğŸ˜´ ëˆ„ì›Œ ìˆê¸° - 'ë‚˜ ì¢€ ë‚´ë²„ë ¤ ë‘¬...' ì™„ë²½í•œ ë¦´ë ‰ìŠ¤~",
    3: "ğŸš€ ë§ˆìš´íŒ… - í•˜ì´í¼ ì—ë„ˆì§€ í’€ê°€ë™!",
    4: "ğŸª‘ ì•‰ì•„ ìˆê¸° - ëŒ•ëŒ•ì˜ ì‹œê·¸ë‹ˆì²˜ í¬ì¦ˆ, 'ë©!'"
}


# MobileNet SSD ëª¨ë¸ ë¡œë“œ
net = cv2.dnn.readNetFromCaffe('MobileNet/deploy.prototxt', 'MobileNet/mobilenet_iter_73000.caffemodel')

# Keypoint ëª¨ë¸ ì •ì˜
class KeypointModel(nn.Module):
    def __init__(self, input_size, num_classes):
        super(KeypointModel, self).__init__()
        self.fc1 = nn.Linear(input_size, 512)
        self.bn1 = nn.BatchNorm1d(512)
        self.fc2 = nn.Linear(512, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.fc3 = nn.Linear(256, 128)
        self.bn3 = nn.BatchNorm1d(128)
        self.dropout = nn.Dropout(0.5)
        self.fc4 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.fc1(x)
        x = nn.ReLU()(self.bn1(x))
        x = self.fc2(x)
        x = nn.ReLU()(self.bn2(x))
        x = self.fc3(x)
        x = nn.ReLU()(self.bn3(x))
        x = self.dropout(x)
        x = self.fc4(x)
        return x

# ëª¨ë¸ ë¡œë“œ
model = KeypointModel(input_size=37, num_classes=5).to(device)
model.load_state_dict(torch.load("best_model.pth", map_location=device))
model.eval()

# Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = Flask(__name__)

# ê°•ì•„ì§€ ê°ì§€ í•¨ìˆ˜
def detect_dog_in_frame(frame):
    blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), (127.5, 127.5, 127.5), swapRB=False)
    net.setInput(blob)
    detections = net.forward()

    dog_boxes = []
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > 0.2:
            class_id = int(detections[0, 0, i, 1])
            if class_id == 12:  # ê°•ì•„ì§€ í´ë˜ìŠ¤
                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])
                (x1, y1, x2, y2) = box.astype("int")
                if x2 > x1 and y2 > y1:
                    dog_boxes.append((x1, y1, x2 - x1, y2 - y1))
    return dog_boxes

# ë¹„ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜
def process_video(file):
    temp_file = tempfile.NamedTemporaryFile(delete=False)
    try:
        file.save(temp_file.name)
        cap = cv2.VideoCapture(temp_file.name)
        if not cap.isOpened():
            raise ValueError("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        keypoints = []
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            dog_boxes = detect_dog_in_frame(frame)
            if dog_boxes:
                keypoints.append(np.random.rand(37)) 
        cap.release()
    finally:
        temp_file.close()
        if os.path.exists(temp_file.name):
            os.remove(temp_file.name)

    if not keypoints:
        raise ValueError("í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")

    return keypoints

# API ì—”ë“œí¬ì¸íŠ¸
@app.route('/analyze', methods=['POST'])
def analyze_video():
    try:
        file = request.files.get('file')
        if not file:
            raise ValueError("íŒŒì¼ì´ ì „ë‹¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        keypoints = process_video(file)
        input_tensor = torch.tensor(keypoints, dtype=torch.float32).to(device)

        with torch.no_grad():
            output = model(input_tensor)
            predicted_classes = torch.argmax(output, dim=1).tolist()

        predicted_behaviors = [behavior_classes.get(cls, "ì•Œ ìˆ˜ ì—†ëŠ” í–‰ë™") for cls in predicted_classes]
        behavior_counts = Counter(predicted_behaviors)
        total_frames = len(predicted_behaviors)
        behavior_percentages = [{"behavior": behavior, "percentage": round((count / total_frames) * 100, 2)} for behavior, count in behavior_counts.items()]
        most_common_behavior = behavior_counts.most_common(1)[0][0]

        return jsonify({
            "frame_by_frame_behavior": predicted_behaviors,
            "behavior_percentages": behavior_percentages,
            "most_common_behavior": most_common_behavior
        }), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
